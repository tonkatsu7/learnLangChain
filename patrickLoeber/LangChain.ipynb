{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tonkatsu7/learnLangChain/blob/main/LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Copyright Â© 2023 Patrick Loeber"
   ],
   "metadata": {
    "id": "DOycdBmh0FBf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://colab.research.google.com/drive/1VOwJpcZqOXag-ZXi-52ibOx6L5Pw-YJi?usp=sharing#scrollTo=nTDgRy0jKDkP"
   ],
   "metadata": {
    "id": "LXWNMCbzHUk1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LangChain\n",
    "\n",
    "LangChain is a framework for developing applications powered by language models.\n",
    "\n",
    "- GitHub: https://github.com/hwchase17/langchain\n",
    "- Docs: https://python.langchain.com/en/latest/index.html\n",
    "\n",
    "### Overview:\n",
    "- Installation\n",
    "- LLMs\n",
    "- Prompt Templates\n",
    "- Chains\n",
    "- Agents and Tools\n",
    "- Memory\n",
    "- Document Loaders\n",
    "- Indexes"
   ],
   "metadata": {
    "id": "nTDgRy0jKDkP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Installation"
   ],
   "metadata": {
    "id": "5WGtOYYTKfz3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiohttp==3.8.4\r\n",
      "aiosignal==1.3.1\r\n",
      "altair==4.2.2\r\n",
      "anyio==3.6.2\r\n",
      "appdirs==1.4.4\r\n",
      "appnope==0.1.2\r\n",
      "argon2-cffi==20.1.0\r\n",
      "asgiref==3.3.4\r\n",
      "astroid==2.5.1\r\n",
      "async-generator==1.10\r\n",
      "async-timeout==4.0.2\r\n",
      "attrs==20.3.0\r\n",
      "Babel==2.9.0\r\n",
      "backcall==0.2.0\r\n",
      "backoff==2.2.1\r\n",
      "black==21.5b0\r\n",
      "bleach==3.3.0\r\n",
      "blinker==1.6.2\r\n",
      "cachetools==5.3.0\r\n",
      "certifi==2020.12.5\r\n",
      "cffi==1.14.5\r\n",
      "chardet==4.0.0\r\n",
      "charset-normalizer==3.1.0\r\n",
      "chromadb==0.3.21\r\n",
      "click==7.1.2\r\n",
      "clickhouse-connect==0.5.22\r\n",
      "colorama==0.4.4\r\n",
      "dataclasses-json==0.5.7\r\n",
      "decorator==4.4.2\r\n",
      "defusedxml==0.7.0\r\n",
      "distlib==0.3.6\r\n",
      "Django==3.2\r\n",
      "duckdb==0.7.1\r\n",
      "entrypoints==0.3\r\n",
      "et-xmlfile==1.1.0\r\n",
      "fastapi==0.95.1\r\n",
      "filelock==3.12.0\r\n",
      "flake8==3.9.1\r\n",
      "frozenlist==1.3.3\r\n",
      "fsspec==2023.4.0\r\n",
      "gitchangelog==3.0.4\r\n",
      "gitdb==4.0.10\r\n",
      "GitPython==3.1.31\r\n",
      "h11==0.14.0\r\n",
      "hnswlib==0.7.0\r\n",
      "httptools==0.5.0\r\n",
      "huggingface-hub==0.14.1\r\n",
      "idna==2.10\r\n",
      "importlib-metadata==6.6.0\r\n",
      "ipykernel==5.5.0\r\n",
      "ipython==7.21.0\r\n",
      "ipython-genutils==0.2.0\r\n",
      "isort==5.7.0\r\n",
      "itsdangerous==1.1.0\r\n",
      "jedi==0.18.0\r\n",
      "Jinja2==3.1.2\r\n",
      "joblib==1.2.0\r\n",
      "json5==0.9.5\r\n",
      "jsonschema==3.2.0\r\n",
      "jupyter-client==6.1.11\r\n",
      "jupyter-core==4.7.1\r\n",
      "jupyter-packaging==0.7.12\r\n",
      "jupyter-server==1.4.1\r\n",
      "jupyterlab==3.0.9\r\n",
      "jupyterlab-pygments==0.1.2\r\n",
      "jupyterlab-server==2.3.0\r\n",
      "langchain==0.0.154\r\n",
      "lazy-object-proxy==1.5.2\r\n",
      "lz4==4.3.2\r\n",
      "markdown-it-py==2.2.0\r\n",
      "MarkupSafe==2.1.2\r\n",
      "marshmallow==3.19.0\r\n",
      "marshmallow-enum==1.5.1\r\n",
      "mccabe==0.6.1\r\n",
      "mdurl==0.1.2\r\n",
      "mistune==0.8.4\r\n",
      "monotonic==1.6\r\n",
      "mpmath==1.3.0\r\n",
      "multidict==6.0.4\r\n",
      "mypy-extensions==0.4.3\r\n",
      "nbclassic==0.2.6\r\n",
      "nbclient==0.5.3\r\n",
      "nbconvert==6.0.7\r\n",
      "nbformat==5.1.2\r\n",
      "nest-asyncio==1.5.1\r\n",
      "networkx==3.1\r\n",
      "nltk==3.8.1\r\n",
      "notebook==6.2.0\r\n",
      "numexpr==2.8.4\r\n",
      "numpy==1.24.3\r\n",
      "openai==0.27.6\r\n",
      "openapi-schema-pydantic==1.2.4\r\n",
      "openpyxl==3.1.2\r\n",
      "packaging==20.9\r\n",
      "pandas==2.0.1\r\n",
      "pandocfilters==1.4.3\r\n",
      "parso==0.8.1\r\n",
      "pathspec==0.8.1\r\n",
      "pexpect==4.8.0\r\n",
      "pickleshare==0.7.5\r\n",
      "Pillow==9.5.0\r\n",
      "pipenv==2020.11.15\r\n",
      "platformdirs==3.5.1\r\n",
      "posthog==3.0.1\r\n",
      "prometheus-client==0.9.0\r\n",
      "prompt-toolkit==3.0.16\r\n",
      "protobuf==3.20.3\r\n",
      "ptyprocess==0.7.0\r\n",
      "pyarrow==12.0.0\r\n",
      "pycodestyle==2.7.0\r\n",
      "pycparser==2.20\r\n",
      "pydantic==1.10.7\r\n",
      "pydeck==0.8.1b0\r\n",
      "pyflakes==2.3.1\r\n",
      "Pygments==2.15.1\r\n",
      "pylint==2.7.2\r\n",
      "Pympler==1.0.1\r\n",
      "pyparsing==2.4.7\r\n",
      "pypdf==3.8.1\r\n",
      "pyrsistent==0.17.3\r\n",
      "python-dateutil==2.8.2\r\n",
      "python-dotenv==1.0.0\r\n",
      "pytz==2021.1\r\n",
      "pytz-deprecation-shim==0.1.0.post0\r\n",
      "PyYAML==6.0\r\n",
      "pyzmq==22.0.3\r\n",
      "regex==2023.3.23\r\n",
      "requests==2.29.0\r\n",
      "rich==13.3.5\r\n",
      "scikit-learn==1.2.2\r\n",
      "scipy==1.10.1\r\n",
      "Send2Trash==1.5.0\r\n",
      "sentence-transformers==2.2.2\r\n",
      "sentencepiece==0.1.98\r\n",
      "six==1.15.0\r\n",
      "smmap==5.0.0\r\n",
      "sniffio==1.2.0\r\n",
      "SQLAlchemy==2.0.12\r\n",
      "sqlparse==0.4.1\r\n",
      "starlette==0.26.1\r\n",
      "streamlit==1.22.0\r\n",
      "sympy==1.11.1\r\n",
      "tabulate==0.9.0\r\n",
      "tenacity==8.2.2\r\n",
      "terminado==0.9.2\r\n",
      "testpath==0.4.4\r\n",
      "threadpoolctl==3.1.0\r\n",
      "tiktoken==0.3.3\r\n",
      "tokenizers==0.13.3\r\n",
      "toml==0.10.2\r\n",
      "toolz==0.12.0\r\n",
      "torch==2.0.0\r\n",
      "torchvision==0.15.1\r\n",
      "tornado==6.1\r\n",
      "tqdm==4.65.0\r\n",
      "traitlets==5.0.5\r\n",
      "transformers==4.28.1\r\n",
      "typing-extensions==4.5.0\r\n",
      "typing-inspect==0.8.0\r\n",
      "tzdata==2023.3\r\n",
      "tzlocal==4.3\r\n",
      "urllib3==1.26.3\r\n",
      "uvicorn==0.22.0\r\n",
      "uvloop==0.17.0\r\n",
      "validators==0.20.0\r\n",
      "virtualenv==20.23.0\r\n",
      "virtualenv-clone==0.5.4\r\n",
      "watchdog==3.0.0\r\n",
      "watchfiles==0.19.0\r\n",
      "wcwidth==0.2.5\r\n",
      "webencodings==0.5.1\r\n",
      "websockets==11.0.2\r\n",
      "Werkzeug==1.0.1\r\n",
      "wrapt==1.12.1\r\n",
      "yarl==1.9.2\r\n",
      "zipp==3.15.0\r\n",
      "zstandard==0.21.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T04:25:49.999624Z",
     "start_time": "2023-05-19T04:25:49.350778Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcrn7QRyQXGj"
   },
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. LLMs\n",
    "\n",
    "A generic interface for all LLMs. See all LLM providers: https://python.langchain.com/en/latest/modules/models/llms/integrations.html"
   ],
   "metadata": {
    "id": "NkGGSdmtta6s"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install openai"
   ],
   "metadata": {
    "id": "H_dfy6G_aBtY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "OPENAI_API_KEY = getpass(\"OpenAI API Key: \")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T02:14:37.145021Z",
     "start_time": "2023-05-29T02:14:33.053907Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "RG = input(\"Azure OpenAI resource group name: \")\n",
    "OPENAI_API_BASE = 'https://' + RG +'.openai.azure.com'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T02:14:45.463559Z",
     "start_time": "2023-05-29T02:14:37.949175Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "os.environ['OPENAI_API_TYPE'] = 'azure'\n",
    "# API version to use (Azure has several)\n",
    "os.environ['OPENAI_API_VERSION'] = '2023-05-01' #'2022-12-01' or '2023-03-15-preview'\n",
    "# base URL for your Azure OpenAI resource\n",
    "os.environ['OPENAI_API_BASE'] = OPENAI_API_BASE"
   ],
   "metadata": {
    "id": "RlxEmS1CaM5v",
    "ExecuteTime": {
     "end_time": "2023-05-29T02:14:46.972282Z",
     "start_time": "2023-05-29T02:14:46.968131Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from langchain.llms import OpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "# llm = OpenAI(temperature=0.9)  # model_name=\"text-davinci-003\"\n",
    "llm = AzureOpenAI(deployment_name=\"gpt301\",\n",
    "                  model_name=\"text-davinci-003\",\n",
    "                  temperature=0.9)\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "print(llm(text))"
   ],
   "metadata": {
    "id": "pY09s9cmZ6nQ",
    "ExecuteTime": {
     "end_time": "2023-05-29T02:14:51.304818Z",
     "start_time": "2023-05-29T02:14:48.126365Z"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BrightToes Socks.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install huggingface_hub"
   ],
   "metadata": {
    "id": "idkq_aVyaceF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"YOUR_HF_TOKEN\""
   ],
   "metadata": {
    "id": "i4DKOWjyaRmO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain import HuggingFaceHub"
   ],
   "metadata": {
    "id": "QmtH72oCaU32"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# https://huggingface.co/google/flan-t5-xl\n",
    "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":0, \"max_length\":64})\n",
    "\n",
    "llm(\"translate English to German: How old are you?\")"
   ],
   "metadata": {
    "id": "8uK5TtJPc49I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Prompt Templates\n",
    "\n",
    "LangChain faciliates prompt management and optimization.\n",
    "\n",
    "Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM."
   ],
   "metadata": {
    "id": "3O-7dO1htdO4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "llm(\"Can Barack Obama have a conversation with George Washington?\")"
   ],
   "metadata": {
    "id": "_FDS9IDRapOt",
    "ExecuteTime": {
     "end_time": "2023-05-18T11:41:58.010164Z",
     "start_time": "2023-05-18T11:41:48.955601Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n\\nNo, Barack Obama cannot have a conversation with George Washington since George Washington is no longer living.'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "prompt = \"\"\"Question: Can Barack Obama have a conversation with George Washington?\n",
    "\n",
    "Let's think step by step.\n",
    "\n",
    "Answer: \"\"\"\n",
    "llm(prompt)"
   ],
   "metadata": {
    "id": "lB4W8dM1tPAY",
    "ExecuteTime": {
     "end_time": "2023-05-18T11:42:37.691434Z",
     "start_time": "2023-05-18T11:42:30.274195Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "' No, Barack Obama cannot have a conversation with George Washington. George Washington passed away in 1799, over 200 years before Barack Obama was born. Moreover, even if it were possible to talk to someone who had died that long ago, the technology to do so does not exist.'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Let's think step by step.\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ],
   "metadata": {
    "id": "UU1VyMMvtsCE",
    "ExecuteTime": {
     "end_time": "2023-05-18T11:43:17.924830Z",
     "start_time": "2023-05-18T11:43:17.912196Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prompt.format(question=\"Can Barack Obama have a conversation with George Washington?\")"
   ],
   "metadata": {
    "id": "-Yzpc_0aHHeE",
    "ExecuteTime": {
     "end_time": "2023-05-18T11:43:24.157445Z",
     "start_time": "2023-05-18T11:43:24.147884Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Question: Can Barack Obama have a conversation with George Washington?\\n\\nLet's think step by step.\\n\\nAnswer: \""
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "llm(prompt)"
   ],
   "metadata": {
    "id": "on8ubh3kt7oD",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:30:54.915552Z",
     "start_time": "2023-05-19T04:30:54.829044Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type PromptTemplate is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-5b4e25c8175c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mllm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprompt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/llms/base.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, prompt, stop, callbacks)\u001B[0m\n\u001B[1;32m    279\u001B[0m         \u001B[0;34m\"\"\"Check Cache and run the LLM on the given prompt and input.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    280\u001B[0m         return (\n\u001B[0;32m--> 281\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgenerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mprompt\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    282\u001B[0m             \u001B[0;34m.\u001B[0m\u001B[0mgenerations\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    283\u001B[0m             \u001B[0;34m.\u001B[0m\u001B[0mtext\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/llms/base.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m(self, prompts, stop, callbacks)\u001B[0m\n\u001B[1;32m    174\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mKeyboardInterrupt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mException\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    175\u001B[0m                 \u001B[0mrun_manager\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_llm_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 176\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    177\u001B[0m             \u001B[0mrun_manager\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_llm_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    178\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/llms/base.py\u001B[0m in \u001B[0;36mgenerate\u001B[0;34m(self, prompts, stop, callbacks)\u001B[0m\n\u001B[1;32m    168\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    169\u001B[0m                 output = (\n\u001B[0;32m--> 170\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_generate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprompts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrun_manager\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrun_manager\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    171\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mnew_arg_supported\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    172\u001B[0m                     \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_generate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprompts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstop\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/llms/openai.py\u001B[0m in \u001B[0;36m_generate\u001B[0;34m(self, prompts, stop, run_manager)\u001B[0m\n\u001B[1;32m    304\u001B[0m                 \u001B[0mchoices\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"choices\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    305\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 306\u001B[0;31m                 \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompletion_with_retry\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprompt\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_prompts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    307\u001B[0m                 \u001B[0mchoices\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"choices\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    308\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstreaming\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/llms/openai.py\u001B[0m in \u001B[0;36mcompletion_with_retry\u001B[0;34m(llm, **kwargs)\u001B[0m\n\u001B[1;32m    104\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mllm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 106\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_completion_with_retry\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    107\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tenacity/__init__.py\u001B[0m in \u001B[0;36mwrapped_f\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    287\u001B[0m         \u001B[0;34m@\u001B[0m\u001B[0mfunctools\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwraps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    288\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mwrapped_f\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 289\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    290\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    291\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mretry_with\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mAny\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mWrappedFn\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tenacity/__init__.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    377\u001B[0m         \u001B[0mretry_state\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRetryCallState\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mretry_object\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    378\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 379\u001B[0;31m             \u001B[0mdo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mretry_state\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mretry_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    380\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDoAttempt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    381\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tenacity/__init__.py\u001B[0m in \u001B[0;36miter\u001B[0;34m(self, retry_state)\u001B[0m\n\u001B[1;32m    312\u001B[0m         \u001B[0mis_explicit_retry\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfut\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfailed\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfut\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTryAgain\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mis_explicit_retry\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretry\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mretry_state\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 314\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfut\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    315\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    316\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mafter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    431\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mCancelledError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    432\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mFINISHED\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 433\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    434\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    435\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py\u001B[0m in \u001B[0;36m__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    387\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    388\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 389\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    390\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    391\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tenacity/__init__.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    380\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDoAttempt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    381\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 382\u001B[0;31m                     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    383\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# noqa: B902\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m                     \u001B[0mretry_state\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexc_info\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[arg-type]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/langchain/llms/openai.py\u001B[0m in \u001B[0;36m_completion_with_retry\u001B[0;34m(**kwargs)\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mretry_decorator\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_completion_with_retry\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 104\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mllm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0m_completion_with_retry\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/api_resources/completion.py\u001B[0m in \u001B[0;36mcreate\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mTryAgain\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0mstart\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py\u001B[0m in \u001B[0;36mcreate\u001B[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m    151\u001B[0m         )\n\u001B[1;32m    152\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 153\u001B[0;31m         response, _, api_key = requestor.request(\n\u001B[0m\u001B[1;32m    154\u001B[0m             \u001B[0;34m\"post\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m             \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/api_requestor.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    218\u001B[0m         \u001B[0mrequest_timeout\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mUnion\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTuple\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    219\u001B[0m     ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], bool, str]:\n\u001B[0;32m--> 220\u001B[0;31m         result = self.request_raw(\n\u001B[0m\u001B[1;32m    221\u001B[0m             \u001B[0mmethod\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    222\u001B[0m             \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/api_requestor.py\u001B[0m in \u001B[0;36mrequest_raw\u001B[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    511\u001B[0m         \u001B[0mrequest_timeout\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mUnion\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTuple\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    512\u001B[0m     ) -> requests.Response:\n\u001B[0;32m--> 513\u001B[0;31m         abs_url, headers, data = self._prepare_request_raw(\n\u001B[0m\u001B[1;32m    514\u001B[0m             \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msupplied_headers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfiles\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequest_id\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    515\u001B[0m         )\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/openai/api_requestor.py\u001B[0m in \u001B[0;36m_prepare_request_raw\u001B[0;34m(self, url, supplied_headers, method, params, files, request_id)\u001B[0m\n\u001B[1;32m    483\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    484\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mparams\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mfiles\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 485\u001B[0;31m                 \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdumps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    486\u001B[0m                 \u001B[0mheaders\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"Content-Type\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"application/json\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    487\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/__init__.py\u001B[0m in \u001B[0;36mdumps\u001B[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001B[0m\n\u001B[1;32m    229\u001B[0m         \u001B[0mcls\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mindent\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mseparators\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    230\u001B[0m         default is None and not sort_keys and not kw):\n\u001B[0;32m--> 231\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_default_encoder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    232\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcls\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    233\u001B[0m         \u001B[0mcls\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mJSONEncoder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/encoder.py\u001B[0m in \u001B[0;36mencode\u001B[0;34m(self, o)\u001B[0m\n\u001B[1;32m    197\u001B[0m         \u001B[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    198\u001B[0m         \u001B[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 199\u001B[0;31m         \u001B[0mchunks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0miterencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_one_shot\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    200\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    201\u001B[0m             \u001B[0mchunks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/encoder.py\u001B[0m in \u001B[0;36miterencode\u001B[0;34m(self, o, _one_shot)\u001B[0m\n\u001B[1;32m    255\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkey_separator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem_separator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msort_keys\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    256\u001B[0m                 self.skipkeys, _one_shot)\n\u001B[0;32m--> 257\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_iterencode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    258\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    259\u001B[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/encoder.py\u001B[0m in \u001B[0;36mdefault\u001B[0;34m(self, o)\u001B[0m\n\u001B[1;32m    177\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    178\u001B[0m         \"\"\"\n\u001B[0;32m--> 179\u001B[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001B[0m\u001B[1;32m    180\u001B[0m                         f'is not JSON serializable')\n\u001B[1;32m    181\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Object of type PromptTemplate is not JSON serializable"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Chains\n",
    "\n",
    "Combine LLMs and Prompts in multi-step workflows"
   ],
   "metadata": {
    "id": "1zw1KlSeuUOY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"Can Barack Obama have a conversation with George Washington?\"\n",
    "\n",
    "print(llm_chain.run(question))"
   ],
   "metadata": {
    "id": "eE6n-jbAuOxt",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:34:26.381491Z",
     "start_time": "2023-05-19T04:33:31.484170Z"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=600).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No, it is not possible for Barack Obama to have a conversation with George Washington because George Washington is no longer alive.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Agents and Tools\n",
    "\n",
    "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
    "\n",
    "\n",
    "When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n",
    "\n",
    "- Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n",
    "- LLM: The language model powering the agent.\n",
    "- Agent: The agent to use.\n",
    "\n",
    "Tools: https://python.langchain.com/en/latest/modules/agents/tools.html\n",
    "\n",
    "Agent Types: https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html"
   ],
   "metadata": {
    "id": "Zp-UlOK0bMVQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ],
   "metadata": {
    "id": "79JcjhFXwv0J",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:34:51.468878Z",
     "start_time": "2023-05-19T04:34:51.460177Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install wikipedia"
   ],
   "metadata": {
    "id": "dOSpaurEb1MR",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:34:57.004880Z",
     "start_time": "2023-05-19T04:34:54.068563Z"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\r\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\r\n",
      "Collecting beautifulsoup4\r\n",
      "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from wikipedia) (2.29.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.12.5)\r\n",
      "Collecting soupsieve>1.2\r\n",
      "  Using cached soupsieve-2.4.1-py3-none-any.whl (36 kB)\r\n",
      "Using legacy 'setup.py install' for wikipedia, since package 'wheel' is not installed.\r\n",
      "Installing collected packages: soupsieve, beautifulsoup4, wikipedia\r\n",
      "    Running setup.py install for wikipedia ... \u001B[?25ldone\r\n",
      "\u001B[?25hSuccessfully installed beautifulsoup4-4.12.2 soupsieve-2.4.1 wikipedia-1.4.0\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.1; however, version 23.1.2 is available.\r\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"
   ],
   "metadata": {
    "id": "RgV4kny1bgy1",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:35:25.982156Z",
     "start_time": "2023-05-19T04:35:25.902485Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ],
   "metadata": {
    "id": "iQUOsWLrbjKv",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:36:08.033799Z",
     "start_time": "2023-05-19T04:36:08.001184Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "agent.run(\"In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the 0.43 power?\")"
   ],
   "metadata": {
    "id": "M8Rob2Wsb_l9",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:36:35.509253Z",
     "start_time": "2023-05-19T04:36:09.796707Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m I need to find out the year the film was released and then use the calculator to calculate the power.\n",
      "Action: Wikipedia\n",
      "Action Input: Departed with Leonardo Dicaprio\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mPage: Leonardo DiCaprio filmography\n",
      "Summary: Leonardo DiCaprio is an American actor who began his career performing as a child on television. He appeared on the shows The New Lassie (1989) and Santa Barbara (1990) and also had long running roles in the comedy-drama Parenthood (1990) and the sitcom Growing Pains (1991). DiCaprio played Tobias \"Toby\" Wolff opposite Robert De Niro in the biographical coming-of-age drama This Boy's Life in 1993. In the same year, he had a supporting role as a developmentally disabled boy Arnie Grape in What's Eating Gilbert Grape, which earned him nominations for the Academy Award for Best Supporting Actor and the Golden Globe Award for Best Supporting Actor â Motion Picture. In 1995, DiCaprio played the leading roles of an American author Jim Carroll in The Basketball Diaries and the French poet Arthur Rimbaud in Total Eclipse. The following year he played Romeo Montague in the Baz Luhrmann-directed film Romeo + Juliet (1996). DiCaprio starred with Kate Winslet in the James Cameron-directed film Titanic (1997). The film became the highest grossing at the worldwide box-office, and made him famous globally. For his performance as Jack Dawson, he received the MTV Movie Award for Best Male Performance and his first nomination for the Golden Globe Award for Best Actor â Motion Picture Drama.In 2002, DiCaprio played con-artist Frank Abagnale, Jr. opposite Tom Hanks in the Steven Spielberg-directed biographical crime-drama Catch Me If You Can and also starred in the Martin Scorsese-directed historical drama Gangs of New York. He founded his own production company, Appian Way, in 2004. The next two films he starred in were both directed by Scorsese: the Howard Hughes biopic The Aviator (2004) and the crime drama The Departed (2006). For his portrayal of Hughes in the former, DiCaprio won the Golden Globe Award for Best Actor â Motion Picture Drama and garnered his first nomination for the Academy Award for Best Actor.DiCaprio produced the environmental documentary The 11th Hour and the comedy drama Gardener of Eden in 2007. The following year, he reunited with Kate Winslet in the Sam Mendes-directed drama Revolutionary Road and appeared in the Ridley Scott-directed action film Body of Lies. DiCaprio reteamed with Scorsese in 2010 in the psychological thriller Shutter Island and also starred in the Christopher Nolan-directed science fiction heist thriller Inception. In 2011, he portrayed J. Edgar Hoover, the first director of the FBI, in the biopic J. Edgar. The following year, he played a supporting role in the Quentin Tarantino-directed western Django Unchained. DiCaprio starred in two film adaptations of novels in 2013; he first appeared as Jay Gatsby in the Luhrmann-directed adaptation of F. Scott Fitzgerald's novel The Great Gatsby, and later as Jordan Belfort in The Wolf of Wall Street, an adaptation of Belfort's memoir of the same name. The latter earned him a third Academy Award nomination for Best Actor and a Golden Globe Award for Best Actor â Motion Picture Musical or Comedy. In 2015, DiCaprio played fur trapper Hugh Glass in the survival drama The Revenant, for which he won the Academy Award for Best Actor.\n",
      "\n",
      "Page: Leonardo DiCaprio\n",
      "Summary: Leonardo Wilhelm DiCaprio (, ; Italian: [diËkaËprjo]; born November 11, 1974) is an American actor and film producer. Known for his work in biographical and period films, he is the recipient of numerous accolades, including an Academy Award, a British Academy Film Award and three Golden Globe Awards. As of 2019, his films have grossed over $7.2 billion worldwide, and he has been placed eight times in annual rankings of the world's highest-paid actors.\n",
      "Born in Los Angeles, DiCaprio began his career in the late 1980s by appearing in television commercials. In the early 1990s, he had recurring roles in various television shows, such as the sitcom Parenthood, and had his first major film part as author Tobias Wolff in This Boy's Life (1993). He received critical acclaim and his first Academy Award and Golden Globe Award nominations for his performance as a developmentally disabled boy in What's Eating Gilbert Grape (1993). DiCaprio achieved international stardom with the star-crossed romances Romeo + Juliet (1996) and Titanic (1997). After the latter became the highest-grossing film at the time, he reduced his workload for a few years. In an attempt to shed his image of a romantic hero, DiCaprio sought roles in other genres, including the 2002 crime dramas Catch Me If You Can and Gangs of New York; the latter marked the first of his many successful collaborations with director Martin Scorsese.\n",
      "DiCaprio earned Golden Globe nominations for his performances in the biopic The Aviator (2004), the political thriller Blood Diamond (2006), the crime drama The Departed (2006) and the romantic drama Revolutionary Road (2008). In the 2010s, he made environmental documentaries and starred in several high-profile directors' successful projects, including the action thriller Inception (2010), the western Django Unchained (2012), the biopic The Wolf of Wall Street (2013), the survival drama The Revenant (2015)âfor which he won the Academy Award for Best Actorâand the comedy-drama Once Upon a Time in Hollywood (2019).\n",
      "DiCaprio is the founder of Appian Way Productionsâa production company that has made some of his films and the documentary series Greensburg (2008â2010)âand the Leonardo DiCaprio Foundation, a nonprofit organization devoted to promoting environmental awareness. A United Nations Messenger of Peace, he regularly supports charitable causes. In 2005, he was named a Commander of the Ordre des Arts et des Lettres for his contributions to the arts, and in 2016, he appeared in Time magazine's 100 most influential people in the world. DiCaprio was voted one of the 50 greatest actors of all time in a 2022 readers' poll by Empire.\n",
      "\n",
      "Page: Martin Scorsese and Leonardo DiCaprio\n",
      "Summary: Martin Scorsese and Leonardo DiCaprio are frequent collaborators in cinema, with DiCaprio appearing in five feature films and one short film made by Scorsese since 2002. The films explore a variety of genres, including historical epic, crime, thriller, biopic, comedy and western. Several have been listed on many critics' year-end top ten and best-of-decade lists.\n",
      "The duo's films have been nominated for thirty-one Academy Awards, winning nine. In 2013, the duo was awarded National Board of Review Spotlight award for career collaboration. Scorsese's work with DiCaprio is considered to be as vital as his work with Robert De Niro.\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I now know the year the film was released.\n",
      "Action: Calculator\n",
      "Action Input: 2006 raised to the 0.43 power\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3mAnswer: 26.30281917656938\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I now know the final answer.\n",
      "Final Answer: The film Departed with Leonardo DiCaprio was released in 2006 and 2006 raised to the 0.43 power is 26.30281917656938.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'The film Departed with Leonardo DiCaprio was released in 2006 and 2006 raised to the 0.43 power is 26.30281917656938.'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Memory\n",
    "\n",
    "Add State to Chains and Agents.\n",
    "\n",
    "Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory."
   ],
   "metadata": {
    "id": "8AuQNfhYm48A"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "\n",
    "conversation.predict(input=\"Hi there!\")"
   ],
   "metadata": {
    "id": "Ujwj29G2cDPN",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:38:44.624108Z",
     "start_time": "2023-05-19T04:38:42.182629Z"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" Hi there! It's nice to meet you. How can I help you today?\""
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "conversation.predict(input=\"Can we talk about AI?\")"
   ],
   "metadata": {
    "id": "XkKv8n7ZnB2e",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:39:26.373549Z",
     "start_time": "2023-05-19T04:39:24.823458Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: Can we talk about AI?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Absolutely! What would you like to know about AI?'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "conversation.predict(input=\"I'm interested in Reinforcement Learning.\")"
   ],
   "metadata": {
    "id": "r4P3zWCmoDST",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:39:37.162790Z",
     "start_time": "2023-05-19T04:39:32.291407Z"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: Can we talk about AI?\n",
      "AI:  Absolutely! What would you like to know about AI?\n",
      "Human: I'm interested in Reinforcement Learning.\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Sure! Reinforcement Learning is a type of machine learning algorithm that allows an AI agent to learn from its environment by taking actions and receiving rewards or punishments. It is used to solve complex problems that require trial and error. Would you like to know more about how it works?'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Document Loaders\n",
    "\n",
    "Combining language models with your own text data is a powerful way to differentiate them. The first step in doing this is to load the data into âdocumentsâ - a fancy way of say some pieces of text. This module is aimed at making this easy.\n",
    "\n",
    "https://python.langchain.com/en/latest/modules/indexes/document_loaders.html"
   ],
   "metadata": {
    "id": "9wMttXM-CuPK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "\n",
    "loader = NotionDirectoryLoader(\"Notion_DB\")\n",
    "\n",
    "docs = loader.load()"
   ],
   "metadata": {
    "id": "iAiISOcboPKR",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:40:47.097431Z",
     "start_time": "2023-05-19T04:40:47.080016Z"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Indexes\n",
    "\n",
    "Indexes refer to ways to structure documents so that LLMs can best interact with them. This module contains utility functions for working with documents\n",
    "\n",
    "- Embeddings: An embedding is a numerical representation of a piece of information, for example, text, documents, images, audio, etc.\n",
    "- Text Splitters: When you want to deal with long pieces of text, it is necessary to split up that text into chunks.\n",
    "- Vectorstores: Vector databases store and index vector embeddings from NLP models to understand the meaning and context of strings of text, sentences, and whole documents for more accurate and relevant search results."
   ],
   "metadata": {
    "id": "Q_zcj8MLDGfQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state_of_the_union.txt\"\n",
    "res = requests.get(url)\n",
    "with open(\"state_of_the_union.txt\", \"w\") as f:\n",
    "  f.write(res.text)"
   ],
   "metadata": {
    "id": "qLU79cyCozYl",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:51:22.944222Z",
     "start_time": "2023-05-19T04:51:22.536135Z"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Document Loader\n",
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('./state_of_the_union.txt')\n",
    "documents = loader.load()"
   ],
   "metadata": {
    "id": "XGyZXiJZBsov",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:51:27.702460Z",
     "start_time": "2023-05-19T04:51:27.689068Z"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Text Splitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ],
   "metadata": {
    "id": "OklI0xTvp2KE",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:51:32.212386Z",
     "start_time": "2023-05-19T04:51:32.182436Z"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install sentence_transformers"
   ],
   "metadata": {
    "id": "skvXSMXHCxyq",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:51:55.066845Z",
     "start_time": "2023-05-19T04:51:53.735109Z"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sentence_transformers) (4.28.1)\r\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sentence_transformers) (4.65.0)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sentence_transformers) (2.0.0)\r\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sentence_transformers) (0.15.1)\r\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sentence_transformers) (1.24.3)\r\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sentence_transformers) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sentence_transformers) (1.10.1)\r\n",
      "Requirement already satisfied: nltk in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sentence_transformers) (3.8.1)\r\n",
      "Requirement already satisfied: sentencepiece in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sentence_transformers) (0.1.98)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sentence_transformers) (0.14.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (20.9)\r\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\r\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.4.0)\r\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.29.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (2.4.7)\r\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\r\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\r\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.3.23)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\r\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from nltk->sentence_transformers) (1.2.0)\r\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from nltk->sentence_transformers) (7.1.2)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2020.12.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.10)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from torchvision->sentence_transformers) (9.5.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.1; however, version 23.1.2 is available.\r\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "#text = \"This is a test document.\"\n",
    "#query_result = embeddings.embed_query(text)\n",
    "#doc_result = embeddings.embed_documents([text])"
   ],
   "metadata": {
    "id": "V1yCdAhSCi64",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:52:56.965454Z",
     "start_time": "2023-05-19T04:52:01.458702Z"
    }
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (â¦)a8e1d/.gitattributes: 100%|ââââââââââ| 1.18k/1.18k [00:00<00:00, 425kB/s]\n",
      "Downloading (â¦)_Pooling/config.json: 100%|ââââââââââ| 190/190 [00:00<00:00, 85.7kB/s]\n",
      "Downloading (â¦)b20bca8e1d/README.md: 100%|ââââââââââ| 10.6k/10.6k [00:00<00:00, 5.33MB/s]\n",
      "Downloading (â¦)0bca8e1d/config.json: 100%|ââââââââââ| 571/571 [00:00<00:00, 191kB/s]\n",
      "Downloading (â¦)ce_transformers.json: 100%|ââââââââââ| 116/116 [00:00<00:00, 48.5kB/s]\n",
      "Downloading (â¦)e1d/data_config.json: 100%|ââââââââââ| 39.3k/39.3k [00:00<00:00, 204kB/s]\n",
      "Downloading pytorch_model.bin: 100%|ââââââââââ| 438M/438M [00:39<00:00, 11.0MB/s] \n",
      "Downloading (â¦)nce_bert_config.json: 100%|ââââââââââ| 53.0/53.0 [00:00<00:00, 16.1kB/s]\n",
      "Downloading (â¦)cial_tokens_map.json: 100%|ââââââââââ| 239/239 [00:00<00:00, 93.0kB/s]\n",
      "Downloading (â¦)a8e1d/tokenizer.json: 100%|ââââââââââ| 466k/466k [00:00<00:00, 924kB/s]\n",
      "Downloading (â¦)okenizer_config.json: 100%|ââââââââââ| 363/363 [00:00<00:00, 197kB/s]\n",
      "Downloading (â¦)8e1d/train_script.py: 100%|ââââââââââ| 13.1k/13.1k [00:00<00:00, 4.09MB/s]\n",
      "Downloading (â¦)b20bca8e1d/vocab.txt: 100%|ââââââââââ| 232k/232k [00:00<00:00, 1.20MB/s]\n",
      "Downloading (â¦)bca8e1d/modules.json: 100%|ââââââââââ| 349/349 [00:00<00:00, 265kB/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install faiss-cpu"
   ],
   "metadata": {
    "id": "8R3pT55b-uBJ",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:53:43.629095Z",
     "start_time": "2023-05-19T04:53:41.670459Z"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\r\n",
      "  Downloading faiss_cpu-1.7.4-cp39-cp39-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "\u001B[K     |ââââââââââââââââââââââââââââââââ| 2.7 MB 3.4 MB/s eta 0:00:01\r\n",
      "\u001B[?25hInstalling collected packages: faiss-cpu\r\n",
      "Successfully installed faiss-cpu-1.7.4\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.1; however, version 23.1.2 is available.\r\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Vectorstore: https://python.langchain.com/en/latest/modules/indexes/vectorstores.html\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "db = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "docs = db.similarity_search(query)"
   ],
   "metadata": {
    "id": "W7sRydnlC7rb",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:53:53.231245Z",
     "start_time": "2023-05-19T04:53:47.647929Z"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(docs[0].page_content)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CB7lvDWzDHZy",
    "outputId": "3b0399d0-6c04-4cef-a029-e48cbd41eedd",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:54:01.643273Z",
     "start_time": "2023-05-19T04:54:01.639908Z"
    }
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while youâre at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, Iâd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyerâan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nationâs top legal minds, who will continue Justice Breyerâs legacy of excellence.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "db.save_local(\"faiss_index\")\n",
    "new_db = FAISS.load_local(\"faiss_index\", embeddings)\n",
    "docs = new_db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ],
   "metadata": {
    "id": "nu-AmhDLEK0h",
    "ExecuteTime": {
     "end_time": "2023-05-19T04:54:52.948049Z",
     "start_time": "2023-05-19T04:54:52.783083Z"
    }
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while youâre at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, Iâd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyerâan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nationâs top legal minds, who will continue Justice Breyerâs legacy of excellence.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## End-to-end example\n",
    "\n",
    "https://github.com/hwchase17/chat-langchain\n"
   ],
   "metadata": {
    "id": "K1lGH_g2--Si"
   }
  }
 ]
}
